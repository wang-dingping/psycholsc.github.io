---
layout: post
comments: true
title:  "水区"
excerpt: "-"
date:   2018-10-20 12:42:24
categories: Notes
---

<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

没有意义的内容全部集中在这里了，不定期更新，日期后注。

---

## 1. ユメセカイ

[ユメセカイ - 戸松遥](http://music.163.com/song?id=417613546&userid=417359311)

第一部中桐老爷在医院醒来后的BGM。

> 想说一句，谷歌和百度的翻译很灵性。我不是很懂日语规则，但是谷歌翻译出来的画风是“Yumesekai”，而百度翻译出来就是“梦世界”。两家的NLP模型看来对语言的处理确实存在一定不同，对于片假名的解读，谷歌倾向于表达注音这个意思，而百度却指出了这个注音可能的含义。如果出现多义性问题，百度的表现就不得而知了w。
>
> 官方翻译应该是“梦想世界”，这段BGM出现的位置，原本标志着川原砾当年对“刀剑神域”这个世界观的描写的结束，但在后来这个故事还是继续延续下去了。从我个人角度来看，SAO的故事如果在这里结束，也是很好的了...后面对这个故事的不断增补，反而给人一种狗尾续貂的感觉。每当听到这个BGM，总会让我想到高三的时候，每天十点十分就会熄灯，而楼管大爷也会在十一点前不断地查房，检查宿舍纪律。楼道中的微弱灯光透过门上的玻璃照到我的床边，光斑大小刚好够放下一本“刀剑神域”。高三下学期最后的时候，很长一段时间，在十一点后我都会从枕头下面拿出这本书逐字逐句地仔细阅读，也算是我高中时期最辛苦的时段中唯一的乐趣了。虽然在看小说的时候从来没有看过动画作品，可是就算是第一次听到这个BGM我也自然地联想到了这个片段，可以说是非常用心的作品了。
>
> 从现实的角度来讲，我可能无论从哪个角度来看都是一个不合格的人。每当这样想的时候，都会想再来听几遍这样的歌曲，好让我尽快抛弃这样的想法。
>
> 2018年10月20日12:42:08

## 2. 微机原理课程设计

**这一段比较长**

TPU是特化的专用处理器。

- 通用处理器

  通用处理器一般指我们目前使用的CPU。相对于专用处理器，其性能没有针对某些特殊任务做特别的优化，因此在各项使用中表现都很正常，没有特别出色的地方。

  - **复杂指令集**（Complex Instruction Set Computing;**CISC**）通用处理器

    目前正在学习的x86（例如8086）就是基于复杂指令集的处理器。复杂指令集是一种微处理器指令集架构，每个指令执行若干低级操作（存储器中读取、存储，计算等，全部集于单一指令中）。复杂指令集指令数目多而杂，且每条指令字长并不相等，计算机必须加以判断读取，在性能上付出代价。

  - **精简指令集**（Reduced Instruction Set Computing;**RISC**）通用处理器

    对指令数目与寻址方式都做了精简，使其实现更容易，指令并行执行程度号，编译器的效率更高。目前而言采用精简指令集的处理器主要是ARM、AVR、MIPS以及IBM的Power Architecture处理器。

    > 题外话，早期计算机行业中编译器技术并不发达，许多程序以机器语言或汇编语言来完成。为了便于程序编写，当年的程序设计者设计出越来越复杂的指令，可以直接对应高级编程语言的高级功能。在那个年代的看法是，硬件设计更加容易一些。
    >
    > 当时的内存还极小，在缺乏内存的条件下，我们需要程序更加精简，毕竟每一字节都很宝贵。因此要对信息做高度编码。当时内存不仅小，而且还慢（磁芯时代），如果我们对信号做高度编码，访问频率可以下降。
    >
    > 上课也讲过寄存器的设计很贵，每多一位就要提高很多成本；而且以当时的设计水平，额外设计更大的寄存器也是难度较高的。
    >
    > 总体来说当时的人们就是又不愿意多花钱，又懒得自己动手，因此编个程序累skr人。微处理器设计师们也尽可能的让每一个指令做更多的工作，这就是复杂指令集。
    >
    > 精简指令集的优化思想主要是
    >
    > 1. 统一指令编码
    > 2. 泛用寄存器
    > 3. 单纯的寻址模式（复杂寻址模式被简单计算指令序列替代）
    > 4. 硬件支持少数数据模式（部分CISC计算机中有处理字节字符串的指令，这在RISC中一般是不会有的）

    明面上看，复杂指令集都是在服务一些性能相对较差的嵌入式设备处理器，大公司中似乎只有IBM在使用复杂指令集。以**Intel**为例，其不使用复杂指令集的原因是考虑到了代码的兼容性问题。实际上Intel在底层设计时也会采用复杂指令集，人家只是不放弃CISC。Intel在进行了多年的尝试（例如Itanium）后最终也发现，RISC和CISC的混合方法可能是最优的。

    > 参考资料1：[Quora: Why didn't Intel move from CISC architecture to RISC architecture?](https://www.quora.com/Why-didnt-Intel-move-from-CISC-architecture-to-RISC-architecture)
    >
    > 参考资料2：[Stack Overflow:Why does Intel hide internal RISC core in their processors?](https://stackoverflow.com/questions/5806589/why-does-intel-hide-internal-risc-core-in-their-processors)

- 专用处理器

  专用处理器常用于特殊任务的高效运算。相比于CPU在图像处理的运算能力上，GPU要强得多。这也是GPU被设计的原因。GPU在浮点运算中的性能远高于CPU，而且对并行计算适应性更高，在PC机中，这就是一块专用处理器。这里不再对专用处理器做展开说明，只对TPU做一点说明。

  21世纪是生命科学的世纪；近年间来看，21世纪似乎又是一个“人工智能”的世纪。人工智能的说法是不妥的，因为我们眼中的人工智能的突破进展，实际上是**处理器性能提升**与**数据量暴增**两个原因共同造成的。语音与图像数据量的增长，以及对海量数据的有效利用促成了目前的计算机视觉以及自然语言处理等行业的发展，其中也离不开深度学习方法的巨大贡献。这里就列举一个实际应用的例子来说明专用处理器的必要性及其性能。

  深度学习领域中的许多运算都是浮点运算，这样的运算让CPU计算起来速度就会慢很多。因此在对神经网络参数做训练时人们会采取GPU进行，其速度会达到CPU的若干倍。但是Google毕竟是Google，不仅在学术上要走在行业的尖端，就连设备也要。为了配合自己发布的深度学习框架TensorFlow，Google还特意设计了一款硬件设备用于深度学习上的运算加速，那就是TPU（**Tensor Processing  Unit**，参考资料[In-Datacenter Performance Analysis of a Tensor Processing Unit](https://arxiv.org/abs/1704.04760)，1704.04760）。文献中主要论证了TPU的可实现性以及其性能指标。

  神经网络中的计算主要是矩阵的乘法、加法与非线性函数。典型的一个运算过程是

  $$y=\sigma(Wx+b)$$

  其中，$$W$$和$$x$$都是矩阵。$$x$$代表运算过程中的变量，常被称为特征(feature)。$$W$$是权值，因此$$Wx$$就是简单的矩阵乘法计算。$$b$$被称为偏置(bias)，整个结构就是一个变量较多的线性函数。然后人们向这个线性运算中添加了一个非线性函数，使结果出现非线性量，$$\sigma$$函数就是一个非线性函数，nn中常见的有Sigmoid，tanh，ReLU，Softmax等。详细内容可以看CS229那篇博客（

  TPU所依赖的基本技术为

  1. 采用低精度（8bit）计算。8个二进制位也就是2个十六进制位。在深度学习的参数计算过程中，经常会对参数进行归一化处理，因为Scale过大或过小的参数可能会促进梯度爆炸与梯度消失，更会导致计算量暴增而降低处理速度。根据上面文献的信息，将数据位数缩减到8bit仍然能够满足运算需求，对深度学习的参数运算影响很小。另外还能显著降低功率（或者说提高 性能/功耗 的效率比值）。
  2. TPU中采用了特殊的运算结构（Systolic Array）。在国内统一翻译为脉动阵列，Systolic是心脏收缩的意思，由于并行数据流经硬件连线接入处理器节点网络，然后数据被组合处理合并或排序并导出成为计算结果，类似人的心脏收缩时的工作流程，因此得名。该阵列往往用于特定操作，例如大规模并行积分、**卷积**、相关或**矩阵**运算。
  3. TPU采用了更大的片上内存，以此来降低对计算机内存的访问
  4. 直接将神经网络中会用到的激活函数算法硬件实现，并为数据运算提供了高级指令。可以将来自TensorFlow的图式运算结构API调用直接转化乘TPU指令。
  5. 相比传统的计算芯片，TPU设计极为简单。

  2016年TPU首次发布，但在这之前就已经在Google的项目中服役，最为出名的项目包括Google街景服务以及DeepMind的围棋软件AlphaGo等。2017年谷歌I/O年会上发布了第二代TPU，2018年五月发布了第三代。初代的TPU在性能上并不能超越同期的GPU，但随着更新迭代，TPU在处理TensorFlow框架下运算的能力越来越强。就在不到两周前，Google发布了一个称为BERT的NLP模型，号称目前最强的NLP模型（确实强=-=）。该模型在训练时会使用到TPU。完全体BERT训练时使用到了64个TPU芯片，总共使用4天时间就完成了训练（这一次训练大约要消耗50000美元）；如果在NVIDIA的Tesla P100处理器上进行训练，恐怕需要8块P100芯片并行训练1年。

1. 详细介绍神经网络的运算

   神经网络的典型计算是

   $$y=\sigma(W·x+b)$$，这个是一个前向传播的过程，可以参考图片

   ![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/Andrew.png)

   每一个神经元上存储的是权重，输入特征x经过特殊的规则与每特定的权重进行乘法运算，可以等效为一个矩阵乘法过程——一个线性过程。增加了偏置后就相当于增加了一个加性值b。经过这样处理后的结果，对其进行$$\sigma$$函数操作，使其可以出现非线性特征。至此神经网络的一个前向传播计算完毕，计算的结果将进行下一层的运算。

2. TensorFlow是什么

   TensorFlow是谷歌开源的一款深度学习框架，实际上是C++底层框架的一个接口。该框架分为Python版和C版，使用起来十分方便，降低搭建深度学习系统的工程量。

3. 脉动阵列（Systolic Array）是如何实现的。Systolic Array实际上不属于SISD，SIMD，MISD，MIMD中的任意一个，而是一种特殊结构。[知乎链接](https://zhuanlan.zhihu.com/p/26522315)给了一个较为清晰的解释，我们可以理解为，将权值矩阵按规则排好顺序，将输入的数据也按顺序排好，然后将权值从上面送入，x从左侧送入，每一个cell进行一次乘法运算，就可以在几个时序后完成整个矩阵的运算。

   ![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/systolicarrayI.jpg)

   ![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/systolicarrayII.jpg)

   ![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/systolicarrayIII.jpg)

   ![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/systolicarrayIV.jpg)

   ![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/systolicarrayV.jpg)



2018年10月21日16:42:08

## 3. 刮墙

温暖的话语总是能够激励人心。

2018年10月22日10:21:20

## 4. 日常

GitHub是炸了吗，怎么push不上去的。

GitHub炸掉的这一段时间里面，发生了很多事情。

tmd都发生完了怎么还没恢复

2018年10月22日22:59:43

今天帮非电子专业的同学简单讲了一下DSP的相关内容，突然发现自己会的好多= =、哪怕只是课内的知识，原来在不经意间已经累积了很多了。

2018年10月24日13:44:40

## 5. 位扩展与字扩展

生产的存储芯片的容量有限，但是随着应用需求的变化，人们对存储芯片的容量有了更高的要求。人们常常将多块相同的存储芯片组合起来形成一个存储容量更大的存储器，组合方式主要是位扩展和字扩展。

1. 位扩展：将数片位数较少的存储芯片组合成位数更多的存储器。就像并联一样。位扩展示意图如下

   ![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/bit_extend.png)

   四块32K 8bit的存储芯片组合为一块32K 32bit的存储器。新的存储器仍然有32K个存储单元，但是每个单元有32bit。对于32K存储器，需要15条地址线，因此地址线从$$A_0$$到$$A_{14}$$。地址线同样的连接到四块芯片上，与此同时还有两条控制线，一个是片选芯片，输入此时的片选信号，如图的$$\overline{CE}$$就是片选信号。$$\overline{OE}$$是另一个控制信号，用于表示此时操作为**读**还是**写**。

   每个存储器都按照存储单元的位数输出8bit的数据线（例如$$D_0$$到$$D_7$$）。如图所示的连接方法，四个8bit数据线构成了32bit数据线。

2. 字扩展：用多片位宽相同的存储器芯片扩展包含更多存储器的过程。就像串联一样。一般是对于每个字的位数足够而字的数目不足的时候使用。字扩展示意图如下：

   ![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/word_extend.png)

   如图我们将两片32K 8bit的芯片组合成一块64K 8bit的存储器。存储器最终是64K，因此需要16根地址线（$$2^{16}=65536=64K$$），数据位数仍然是8bit，因此需要8根数据线。但是每个芯片都是32K，因此需要15根地址线。进行级联后第16根地址线$$A_{15}$$需要连接到一个译码器，输出信号即为片选信号。该片选信号选择此时读写的芯片。

3. 例题1，对于8086CPU，用RAM芯片6264组成32KB 存储空间，地址范围为00000H～07FFFH，画出连接控制原理图（用74138译码器产生片选信号）。

   6264芯片是一个8K 8bit的存储芯片。如果要扩展为32K 16bit的存储器，则需要8块存储器。其中两个一组做位扩展，四组一起做字扩展。8086提供了20条地址线，此处总容量为32K，则可以使用15条地址线做寻址，输出是16位，则对应16bit总线。剩余五条总线可以用来分配为片选。

   8086内存组织如下。20条地址线，可以寻址1MB的存储空间，00000H~FFFFFH。一般是两个512KB存储器组成，一个是奇地址存储器（高字节），与数据总线高八位相连；一个是偶地址存储器（低字节），与数据总线8位相连。两个存储器均与$$A_{19}-A_1$$连接。

    ![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/8086ram.png)

   以上是8086的内存组织，一般19-1的19条地址总线进入地址锁存器，并由锁存器送入奇偶存储芯片中；$$\overline{BHE}$$和$$A_0$$进行片选，选择奇地址与偶地址对应的芯片。两个各8bit的数据线分别连接到数据总线中。

   我们说构成32KB存储器，就是32K 8bit大小的存储器，实际上可以是16K 16bit存储器，大小是等效的。考虑到8086的结构就是16bit数据线，因此就可以采用16K 16bit方案。此时一共需要四片。

   针对位扩展问题，我们采用两片一组的方式，这时构成8K 16bit的单个存储器；然后对于32KB存储，按照8086的规则应当分解为两个16K 8bit存储器，因此对每组进行字扩展到16K，相当于奇偶地址的存储器各使用2个存储芯片。

   接下来的内容可以有多种理解方式。奇偶存储单元每一侧都需要16K的寻址，因此需要14根地址线。而实际上进入后只有13根地址线进行8K寻址，另一个作为片选信号了。所以也可以认为是13条地址线进行寻址。$$A_0$$用于奇偶片选，用于选择高低位，$$A_{14}$$进行片选，用于选择内存前半部分和后半部分（字扩展片选）。

   总结起来就是13条进行实际寻址，0和14条进行片选。

    ![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/eg1.png)

   7FFFH=0111 1111 1111 1111


4. 例题2，对于8086CPU，用RAM芯片6264组成32KB 存储空间，地址范围为50000H～57FFFH，画出连接控制原理图（用门电路产生片选信号） 。

   相比上一个例题，地址发生了变化。

   50000H=0101 0000 0000 0000 0000

   57FFFH=0101 0111 1111 1111 1111

   实际上还是相同的空间，只是最高位发生了改变，总大小不发生改变。看一看答案还是很容易懂的。

    ![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/eg2.png)



## 6. 日常

今天大家在群里给龙神策划生日。提前了一周时间，还邀请了龙神最好最熟悉的朋友们。

龙神说自己喜欢吃小龙虾，我们找遍了中关村的店，也不能在人均两位数解决问题。

在大家最后决定高价解决问题的时候我也是想退出的

最后还是决定为了这个好朋友搏一把。

真羡慕这样的人，能有我们这样的朋友。

二十年了，**从来没有人**能替我策划一次生日，安排surprise。一股莫名的悲伤一下子涌上来了。

**我永远属于那种隐形人物。**

**也不配拥有这样的好朋友。**



**2018年10月27日00:45:06**

## 7. 日常

狗屎微电子工艺实验

2018年10月28日09:31:12

## 8. 日常

雅思发广告的人对我发动了一次道德攻击，要不是有人劝我我都快内疚死了，草。

先给我发了个文件袋，我收下了，然后让我扫码，我不太想扫，但是拿人家东西又不太好，所以还给人家了。

然后他对我说了声**谢谢**

草

这个场面就像是我拒绝了一个在严寒中发小广告的人，还对人家的工作表现出了强烈的不屑以及贪图小利的小人心理

我草草草这个人有点骚

2018-11-10 00:15:17

## 9. 待办备忘

1. 该开始复习了草
2. 通信仿真是个啥玩意
3. **安排个放大器**
4. 

## 10. 如何让耳朵变成耳机的形状

32$$\Omega$$的耳机就这么难出声了，没想到耳机是这么难伺候的东西。

目前感觉是，直推声音没有多少低频分量，声音集中在人声及以上的频段，这就很狗屎了。如果Windows声音控制器是线性的，至少现在低频低3dB-6dB的增益，需要脑放和耳放来补充。这时候已经为信仰充值了，接下来必须要让耳朵变成耳机的形状了，先听一个月。

但是DT880的声音真的是一言难尽，如果为了杂食听歌还不如买HD650。当年最出名的三款2k元级耳机，HD650，DT880，K701，现在只有森海还维持在2K元级，从不降价，DT880已经降到了相对合理的1500元级别，而K701因为难伺候的原因，现在已经降到8-900元了。侧面表现我应该买一个HD650，又好伺候又好听。

2018-11-14 10:50:04

你说这个低阻抗的IE60怎么就这么好听呢。

2018-11-14 11:05:53

## 11. 日常

无事发生（X

2018-11-14 11:08:52

## 12. 日常

耳朵快要被DT880惯坏了。听完了大耳880终于听出来了IE60声音到底哪里不足，某种意义上规正了听音观。DT880的声音是真的好听，适合我这样不那么追求刺激低频的老年人，中高频的解析力真的很强，不过没有什么合适的设备能够较好地驱动。

看了一下价格，DT990已经降价到1300以下了，看风评DT990似乎更均衡一些，不过无妨，他没880好看。

2018-11-18 23:05:30



## 13. 日常

我操这人好贱啊，居然对老实人下手。

大学期间见过最贱的人了。

想起来《人渣的本愿》了，艺术果然取自生活，这回没能高于生活。

2018-11-19 15:30:37

## 14. 数字图像处理课程设计 - Style Transfer

### 14.1 CNN 模型

#### 14.1.1 CNN的历史

- CNN最早可以追溯到1968年，Hubel和Wiesel发表了一篇论文，文中讲述了猫和猴的视觉皮层中含有对视野的小区域单独反应的神经元。文中提出的**感受野**概念为CNN的局部感知奠定了基础。
- 1980年神经感知机出现，标志着第一个初始的卷积神经网络诞生。神经感知机将一个视觉特征分解成许多子特征，通过分层递接相连的特征平面进行处理。
- 上世纪的发展始终较为缓慢，受限于数据量与计算力，大多数进展仅仅局限于理论
- 2005年左右，人们利用GPU实现了CNN的加速运算，一种使用专用加速的CNN处理方式出现，从而使得CNN重新发展，深度学习也进入了大众视野。
- 2012年ImageNet大赛中，CNN首次夺得冠军，并大幅超越其他算法

#### 14.1.2 CNN基本结构

CNN由输入层、输出层以及多个隐藏层组成。这个结构和传统的nn结构相同，通过输入层将数据送入网络，网络中进行运算后从输出层输出。中间的隐藏层一般包括卷积层、池化层、ReLU层和全连通层。从我个人理解，**卷积层**使用类似卷积的方式减少运算参数，并抽取图像的信息，**池化**实际上是一个降采样，也分很多种；**ReLU**是线性整流单元的缩写，与此相关的是机器学习中的一些非线性函数。其他类似的函数还有`Sigmoid`，`tanh`等，此处不再介绍其性质。经过试验验证、理论证明，可以知道ReLU在处理此类问题上不仅高效而且效果较好；**全连通层**作用其实是线性变换。

数字图像可以理解为一个矩阵，拥有多个通道的彩色图像就是一个张量。TensorFlow的取义就是张量流，数据都是以张量形式在网络中流动的，因此张量可以作为网络的输入。

图像经过输入层后来到隐藏层。首先介绍卷积层。

- 卷积层是CNN的核心，卷积层可以理解为是一组可以被训练的滤波器。卷积层一般有较小的感受野，常见的卷积核也就3×3或5×5，在VGG的一些模型中还出现过1×1的卷积核作特殊用途。在网络的前馈过程中，卷积核对图像进行卷积，然后将结果进行输出（有时会通过激活函数后输出）。

    实际上图像的卷积有相关的含义，与我们课程中的相关运算很像，我们可以理解为卷积过程在进行相关匹配，以此来提取更高层次的特征。例如我们使用的`Sobel`算子，就会匹配与算子相似的特征。

- 池化层的目的就是下采样，降低数据量的方式。数字图像中数据量较多，通过池化的方法降低数据量，实际还可以让滤波器匹配更大的特征（降低了图像的特征尺寸）。常见的池化方式有最大池化`max_pooling`，工作方式如图

     ![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/maxpooling.png)

- ReLU线性整流单元，实际曲线如图

     ![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/ReLU.png)

     主要作用在于添加非线性量。

- 输出层，一般对于分类器模型，会采用$$Softmax$$等函数作为输出层，用于将结果转化为决策数值。

- 全连通层，常规神经网络，就相当于对图片应用一定维度的矩阵线性变换。

#### 14.1.3 CNN的特点

1. 局部感知
    - 卷积核大小固定，因此感知区域有限。提升感知能力（**由局部到整体**）通过池化和全连通层完成。
    - 传统的nn结构只能对整体作分析
2. 权重共享
    - 传统nn的参数量巨大。如果对一张1000\*1000的图像作分析，想要映射到和原图相同大小的矩阵中，根据全连接的定义，将需要1000\*1000\*1000\*1000个参数，运用卷积的方法可以有效降低参数的数量。
3. 多卷积核
    - 每个卷积核可以代表一种特征，如果采用多卷积核，就能获取不同特征的集合。

### 14.2 Neural Style

#### 14.2.1 思路

论文1508.06576v2（ArXiv）,A neural algorithm of artistic style,发表于CVPR16时有修改，题目为Image Style Transfer Using Convolutional Neural Networks，内容大体相似。

该算法在2016年时大受推崇，结果直观，理论简介，且容易在各种平台复现。本次采用`TensorFlow`进行复现。

本算法实现的思路为

1. 使用**现成**的**识别网络**，提取图像的不同层级的特征
2. 低层的响应描述了图像的**大体风格**，高层次的响应描述了图像的**内容**。
3. 采用梯度下降方法优化**输入响应**，使得我们在特定层获取特定响应。
4. 经过足够次数的迭代，输入响应就获得了特定的风格与内容。

如果说mnist拥有五层卷积层和三层全连接层只是一个简单的机器学习任务，那不得不说，本项目的实现是依赖了如假包换的**深度学习**。

#### 14.2.2 VGG

基于深度卷积神经网络的图像识别模型很多，例如GoogleNet、LeNet等，此处选择的VGG模型也是其中的一种。VGG取义`Oxford Visual Geometry Group`，隶属于1985年成立的机器人研究组，这个模型实际上与传统的CNN模型并无较大差异（或者说就是一个较为复杂的CNN模型）。在图像分类比赛中获取过较好的成绩。其模型的结构为

![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/VGG.png)

#### 14.2.3 响应（内容）逼近

对于每一个网络层，实际上输出结果可以表示为

$$x_{t+1}=f(Wx_t+b)$$

其中网络的权重为$$W$$，$$x_t$$是前一层的输出，$$x_{t+1}$$是当前层的输出。论文中指出，这个池化采用了average_pooling，据说可以略微提升效果。

这个(pretrained) VGG网络是现成的、训练好的，不需要我们做额外的操作就能够在低层级输出图片的小区域的信息（边角、曲线），中间层输出较大尺度的信息（方块、螺旋），高层级输出最大尺度的信息（图片的总体内容信息）

接下来需要调教网络的响应。将这个网络视为一个系统（非线性系统）

**任取一个图像**$$X^0$$，将其输入上述的网络中，第$$l$$卷积层的响应我们记为$$X^l$$，其尺寸为$$H^l \times  W^l \times N^l$$。

即对于输入$$X^0$$，得到系统响应为$$X^l$$。

对于我们的**目标图像**$$\overline{X^0}$$，送入同样的网络，同样可以得到第$$l$$层响应为$$\overline{X^l}$$。

即对于输入$$\overline{X^0}$$，得到系统响应为$$\overline{X^l}$$。

如果我们希望调整系统的输入，使得两个输入变得相似，一个可行的方法就是调整其响应。视**确定风格**的图像的响应为固定值，修改目标图像的响应，就可以让目标图像在某种程度上接近**风格图像的风格**。

这个调整过程是神经网络优化算法中常见的反向传播方法。假设我要调整第$$l$$层的误差，我们就可以设计范数误差函数

$$E_c^l=\frac{1}{2}\mid \mid X^l-\overline{X^l}\mid \mid ^2$$

两个响应的误差如上，想要最小化误差，对该误差函数进行求导，即得

$$\frac{\partial E_c^l}{x^l_{h,w,k}}=x^l_{h,w,k}-\overline{x^l_{h,w,k}}$$

被求导对象是本层的所有元素，$$h$$是本卷积层输出响应的高度，$$w$$是宽度，$$k$$是个数。

用此图辅助理解

![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/mnistCNN.png)

进一步的，运用链式求导法则，将误差反向传播到输入层，整个过程就是反向传播。

*通过第一次求导，可以得出前一层的误差，第二次求导获取更前一层的误差，通过多次的链式求导，就能求得最前一层的误差，我们按照梯度方向进行修正，就能让输入图像的==内容==更加接近。*

#### 14.2.3 风格逼近

风格是没有位置关系的。

**格拉姆矩阵**（Gram Matrix），协方差矩阵。格拉姆矩阵的定义为

$$\Delta (\alpha_1,\alpha_2,...,\alpha_k)=\left[ \begin{matrix}(\alpha_1,\alpha_1) & (\alpha_1,\alpha_2) & ... & (\alpha_1,\alpha_k)\\ (\alpha_2,\alpha_1) & (\alpha_2,\alpha_2) & ... & (\alpha_2,\alpha_k)\\ ...&...&...&... \\ (\alpha_k,\alpha_1) & (\alpha_k,\alpha_2) & ... & (\alpha_k,\alpha_k)\end{matrix} \right]$$

其中括号表示内积。

实际上可以用来判断特征之间的偏心协方差（未减去均值的协方差矩阵）。论文中采用Gram矩阵为

$$G_{i,j}^l=\sum\limits_{hw}x_{j,w,i}^l · x_{h,w,j}^l$$

即第$$l$$层的格拉姆矩阵用作特征矩阵，由于计算方法抛弃了位置信息，因此可以看做是对风格的描述。第$$i,j$$位置的元素用于描述第$$i$$和第$$j$$个响应的相关性。这可以看作是一个图形风格的代表。

为了让风格像上面的内容一样得到近似，我们采用相似的方法进行逼近。

$$E_c^l=\frac{1}{2}\mid \mid G^l-\overline{G^l}\mid \mid ^2$$

对误差求导可以得到

$$\frac{\partial E_s^l}{x^l_{h,w,k}}=(X^l)^T(G^l-\overline{G^l})_{i,j}$$

同样通过反向传播法则可以使目标图像和我们选取的图像风格逼近。

![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/StyleExperiment.png)

#### 14.2.4 测试

为了不失一般性，采用高斯噪声作为初始输入图像，选取一幅特殊风格的图像作为参考。其中

代表了内容特征的卷积层选择$$conv4\_2$$

代表了风格特征的卷积层选择$$conv1\_1,conv2\_1,conv3\_1,conv4\_1,conv5\_1$$

设内容误差权重为$$\alpha$$，设风格误差权重为$$\beta$$，则误差函数可以联合为

$$Loss_{total} = \alpha Loss_{content}+\beta Loss_{style}$$

即

$$Loss_{total} = \frac{1}{2}\alpha \mid \mid X^l-\overline{X^l}\mid \mid ^2+\beta \frac{1}{2}\mid \mid G^l-\overline{G^l}\mid \mid ^2$$

以下是训练了100次后的结果，耗时约10分钟。

![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/1542695387.result.png)



