---
layout: post
title:  "数字图像处理"
excerpt: "="
date:   2018-11-16 23:54:54 +0000
categories: Notes
comments: true
---

# 数字图像处理

- 期末考试**60**分
- 平时成绩**40**分
- 参考资料 - 冈萨雷斯《数字图像处理》

## 第一章 绪论

1. 数字图像处理的主要内容（基本步骤）

    课程涵盖内容主要包括图像的获取与表示，图像增强，图像复原，压缩编码，图像分割，图像分析。

    数字图像处理一般包含**图像采集（模拟图像的数字化）**，**图像重建**，**图像变换**、**滤波、增强、复原、拼接**等，**图像的压缩与编码**，图像的数字水印和信息隐藏等。

    数字图像分析一般包含边缘检测，图像分割，目标表达、描述、测量，目标形状纹理运动等分析、目标检测提取跟踪识别分类等

    图像理解不在课程要求内。

    课本中描述为：

    图像获取、图像滤波与增强、图像复原、彩色图像处理、小波域多分辨率处理、压缩、形态学处理、分割、表示与描述、目标识别。

2. 根据成像信息源，数字图像处理的主要应用有哪些（电磁波不同波段成像的特点与应用）

    数字图像有将度高，可重复性好，通用性、灵活性强等优点。

    - 伽马射线成像

        核医学、天文观测。医学中人摄入放射性同位素后，在其衰变过程中就会放射伽马射线，以此可以做伽马射线成像。可用于判断骨骼病变位置，感染或肿瘤等。

    - X射线成像

        医学诊断、工业以及其他领域。X射线穿透需要成像的物体后发生衰减，落在底片上之后感光成像。工业应用有电路缺陷检测、金属元件探伤等。

    - 紫外波段成像

        紫外光谱应用较多，平板印刷、工业检测、显微方法、天文观测、生物成像等。常见应用有紫外荧光显微方法以及紫外成像的天文摄影等。

    - 可见光以及红外波段成像

        天文、遥感等领域应用。制药工艺中常会采用可见光的显微技术观测，而遥感中常用红外。还有天气观测等其他应用。

    - 微波波段成像

        雷达成像。一些波段的微波容易穿透云层，从而达到探测与成像等效果。

    - 无线电波段成像

        医学与天文学。核磁共振中常用此类技术。

    - **其他成像**

        声音成像（B超、地质探测、海洋探测），电子成像（电子显微镜）。

## 第二章 数字图像基础

1. 图象数字化包括哪两个过程？数字化参数对图像质量有何影响？

    采样与量化。在满足采样定理的条件下，图像损失较少。量化过程中采用了256量化级数，将连续信息保存到离散点上的离散值。图像信息在此处会被叠加噪声（量化噪声）。采样点数越多，其分辨率越高，数字图像的质量也越高。

2. 人眼中两类光感受细胞锥状体细胞与杆状体细胞的主要功能与特点？

    视锥细胞和视杆细胞都是视网膜上的光感受器，其中视锥细胞在每只眼中约有600万-700万个，主要位于视野的中央凹位置，对颜色高度敏感，可以充分分辨图像的细节，眼球的转动不会对视锥细胞的位置产生影响；视杆细胞大约有7500万到15000万个，主要用于给出视野内的总体图像，但是不感知色彩，对低照度敏感，分布范围较大，但是多个细胞共用一个神经末梢，导致其分辨能力较差。

3. 白天进入一个黑暗剧场的时候，想要看清并找到空座位时眼睛需要适应一段时间，试图描述发生这种现象的视觉原理。

    白天光照较强，此时主要是视锥细胞起主要的视觉作用（视锥细胞对高亮度敏感，对色彩敏感），称为白昼视觉或亮视觉；而视杆细胞主要对低亮度敏感，因此在白天时并不起主要作用，称为暗视觉或微光视觉。白天进入黑暗的剧场时，由于视觉并不能同时在大范围内工作，因此起主要作用的视锥细胞会渐渐失去作用，视杆细胞逐渐开始起主要作用。这个切换过程需要一定时间，因此需要适应一段时间。

4. 图像的形成模型；同态滤波

    人眼中图像的生成主要依赖于人眼的类凸透镜成像和人眼对可见光的反应。

    用函数$$f(x,y)$$来表示图像，其中$$f$$是正标量0-255。一般的其物理意义由像源决定，$$f$$可以由两个分量来表征

    - 入射分量 - 入射到被观察场景的光源照射总量
    - 反射分量 - 场景中物体所反射的光照总量

    单位都是流明（照度）。

    $$f(x,y)=i(x,y)r(x,y)​$$

    入射分量可以是0到无穷之间变化，反射分量是一个相对数值，在0到1之间变化。

    视网膜将图像聚集在中央凹附近，光接收器对光的刺激产生感知，把辐射转变为电脉冲，经大脑解码生成图像。

5. 马赫带现象、对比度、空间、灰度分辨率

    奥地利物理学家马赫发现的视觉效应，观察两块亮度不同的区域时，边界处亮度对比加强，使轮廓表现得特别明显。

    对比度是一幅图像中明暗区域**最亮的白和最暗的黑**之间的比值。

    空间分辨率是图像中可分辨的最小细节度量。数量上有很多方法来说明。

    灰度分辨率，灰度级中可分辨的最小变化。一般是2的整数次幂。通用的是8bit，但是在一些特殊用途中也会出现16bit。

6. 为什么大口径镜头的照相机成像清晰？（其他工艺水平相同的情况下）

    CCD传感器阵列中，每个传感器的响应正比于投射到传感器表面的总能量，提高口径就可以增大单位时间内投射到表面的能量，从而降低噪声。

7. 4邻域、8邻域、视觉感知要素、人眼对亮度的适应范围；视觉错觉；电磁波不同波段成像特点

    一个点的上下左右四个点被称为4邻域

    一个点的四个角的四个相邻点被称为8邻域














## Extra - 数字图像处理课程设计 - Style Transfer

传统数字图像处理是针对图像的传统特征进行增强或修改，这些特征往往是人为设定的。基于CNN的图像处理实际上也是针对特征的处理，但是特征与传统的特征不同。CNN中的卷积核一般是需要网络自行优化的，与人为设计相比，在不同的处理任务中，卷积核可能并不相同，也不需要人为额外设计。

### 1. CNN 模型

#### 1.1 CNN的历史

- CNN最早可以追溯到1968年，Hubel和Wiesel发表了一篇论文，文中讲述了猫和猴的视觉皮层中含有对视野的小区域单独反应的神经元。文中提出的**感受野**概念为CNN的局部感知奠定了基础。
- 1980年神经感知机出现，标志着第一个初始的卷积神经网络诞生。神经感知机将一个视觉特征分解成许多子特征，通过分层递接相连的特征平面进行处理。
- 上世纪的发展始终较为缓慢，受限于数据量与计算力，大多数进展仅仅局限于理论
- 2005年左右，人们利用GPU实现了CNN的加速运算，一种使用专用加速的CNN处理方式出现，从而使得CNN重新发展，深度学习也进入了大众视野。
- 2012年ImageNet大赛中，CNN首次夺得冠军，并大幅超越其他算法

#### 1.2 CNN基本结构

CNN由输入层、输出层以及多个隐藏层组成。这个结构和传统的nn结构相同，通过输入层将数据送入网络，网络中进行运算后从输出层输出。中间的隐藏层一般包括卷积层、池化层、ReLU层和全连通层。从我个人理解，**卷积层**使用类似卷积的方式减少运算参数，并抽取图像的信息，**池化**实际上是一个降采样，也分很多种；**ReLU**是线性整流单元的缩写，与此相关的是机器学习中的一些非线性函数。其他类似的函数还有`Sigmoid`，`tanh`等，此处不再介绍其性质。经过试验验证、理论证明，可以知道ReLU在处理此类问题上不仅高效而且效果较好；**全连通层**作用其实是线性变换。

数字图像可以理解为一个矩阵，拥有多个通道的彩色图像就是一个张量。TensorFlow的取义就是张量流，数据都是以张量形式在网络中流动的，因此张量可以作为网络的输入。

图像经过输入层后来到隐藏层。首先介绍卷积层。

- 卷积层是CNN的核心，卷积层可以理解为是一组可以被训练的滤波器组。卷积层一般有较小的感受野，常见的卷积核也就3×3或5×5，在VGG的一些模型中还出现过1×1的卷积核作特殊用途。在网络的前馈过程中，卷积核对图像进行卷积，然后将结果进行输出（有时会通过激活函数后输出）。

    实际上图像的卷积有相关的含义，与我们课程中的相关运算很像，我们可以理解为卷积过程在进行相关匹配，以此来提取更高层次的特征。例如我们使用的`Sobel`算子，就会匹配与算子相似的特征。

- 池化层的目的就是下采样，降低数据量的方式。数字图像中数据量较多，通过池化的方法降低数据量，实际还可以让滤波器匹配更大的特征（降低了图像的特征尺寸）。常见的池化方式有最大池化`max_pooling`，工作方式如图。

    ![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/maxpooling.png)

    本次按照论文所述，将采用平均池化，即对每个窗内的像素求平均值。

- ReLU线性整流单元，在《随机信号分析》中学到过，是一种非线性元件/函数。实际曲线如图

    ![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/ReLU.png)

    主要作用在于添加非线性量。

- 输出层，一般对于分类器模型，会采用$$Softmax$$等函数作为输出层，用于将结果转化为决策数值。也有直接输出结果的，本次就采用直接输出。

- 全连通层，常规神经网络，就相当于对图片应用一定维度的矩阵线性变换。

#### 1.3 CNN的特点

1. 局部感知
    - 卷积核大小固定，因此感知区域有限。提升感知能力（**由局部到整体**）通过池化和全连通层完成。
    - 传统的nn结构只能对整体作分析
2. 权重共享
    - 传统nn的参数量巨大。如果对一张1000\*1000的图像作分析，想要映射到和原图相同大小的矩阵中，根据全连接的定义，将需要1000\*1000\*1000\*1000个参数，运用卷积的方法可以有效降低参数的数量。
3. 多卷积核
    - 每个卷积核可以代表一种特征，如果采用多卷积核，就能获取不同特征的集合。

### 2 Neural Style

#### 2.1 思路

论文1508.06576v2（ArXiv）,**A neural algorithm of artistic style**,发表于CVPR16时有修改，题目为**Image Style Transfer Using Convolutional Neural Networks**，内容大体相似。

该算法在2016年时大受推崇，**结果直观**，**理论简介**，且**容易**在各种平台**复现**。本次采用`TensorFlow`进行复现。

本算法实现的思路为

1. 使用**现成**的**识别网络**，提取图像的不同层级的特征
2. 低层的响应描述了图像的**大体风格**，高层次的响应描述了图像的**内容**。
3. 采用梯度下降方法优化**输入响应**，使得我们在特定层获取特定响应。
4. 经过足够次数的迭代，输入响应就获得了特定的风格与内容。

如果说mnist拥有五层卷积层和三层全连接层只是一个简单的机器学习任务，那不得不说，本项目的实现是依赖了如假包换的**深度学习**。

#### 2.2 VGG

基于深度卷积神经网络的图像识别模型很多，例如GoogleNet、LeNet等，此处选择的VGG模型也是其中的一种。VGG取义`Oxford Visual Geometry Group`，隶属于1985年成立的机器人研究组，这个模型实际上与传统的CNN模型并无较大差异（或者说就是一个较为复杂的CNN模型）。在图像分类比赛中获取过较好的成绩。其模型的结构为

![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/VGG.png)

#### 2.3 响应（内容）逼近

对于每一个网络层，实际上输出结果可以表示为

$$x_{t+1}=f(Wx_t+b)$$

其中网络的权重为$$W$$，$$x_t$$是前一层的输出，$$x_{t+1}$$是当前层的输出。论文中指出，这个池化采用了average_pooling，据说可以略微提升效果。

这个(pretrained) VGG网络是现成的、训练好的，不需要我们做额外的操作就能够在低层级输出图片的小区域的信息（边角、曲线），中间层输出较大尺度的信息（方块、螺旋），高层级输出最大尺度的信息（图片的总体内容信息）

接下来需要调教网络的响应。将这个网络视为一个系统（非线性系统）

**任取一个图像**$$X^0$$，将其输入上述的网络中，第$$l$$卷积层的响应我们记为$$X^l$$，其尺寸为$$H^l \times  W^l \times N^l$$。H是该层输出的高度，W是该层输出的宽度，N是滤波器组的数量。

即对于输入$$X^0$$，得到系统响应为$$X^l$$。

对于我们的**目标图像**$$\overline{X^0}$$，送入同样的网络，同样可以得到第$$l$$层响应为$$\overline{X^l}$$。

即对于输入$$\overline{X^0}$$，得到系统响应为$$\overline{X^l}$$。

如果我们希望调整系统的输入，使得两个输入变得相似，一个可行的方法就是调整其响应。视**确定风格**的图像的响应为固定值，修改目标图像的响应，就可以让目标图像在某种程度上接近**风格图像的风格**。

这个调整过程是神经网络优化算法中常见的反向传播方法。假设我要调整第$$l$$层的误差，我们就可以设计范数误差函数

$$E_c^l=\frac{1}{2}\mid \mid X^l-\overline{X^l}\mid \mid ^2$$

有关梯度下降法的相关内容可以看CS229那一篇文章的介绍。

用此图辅助理解

![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/mnistCNN.png)

进一步的，运用链式求导法则，将误差反向传播到输入层，整个过程就是反向传播。

*通过第一次求导，可以得出前一层的误差，第二次求导获取更前一层的误差，通过多次的链式求导，就能求得最前一层的误差，我们按照梯度方向进行修正，就能让输入图像的==内容==更加接近。*

#### 2.4 风格逼近

风格是没有位置关系的。

**格拉姆矩阵**（Gram Matrix），协方差矩阵。格拉姆矩阵的定义为

$$\Delta (\alpha_1,\alpha_2,...,\alpha_k)=\left[ \begin{matrix}(\alpha_1,\alpha_1) & (\alpha_1,\alpha_2) & ... & (\alpha_1,\alpha_k)\\ (\alpha_2,\alpha_1) & (\alpha_2,\alpha_2) & ... & (\alpha_2,\alpha_k)\\ ...&...&...&... \\ (\alpha_k,\alpha_1) & (\alpha_k,\alpha_2) & ... & (\alpha_k,\alpha_k)\end{matrix} \right]$$

其中括号表示内积。

实际上可以用来判断特征之间的偏心协方差（未减去均值的协方差矩阵）。论文中采用Gram矩阵为

$$G_{i,j}^l=\sum\limits_{hw}x_{j,w,i}^l · x_{h,w,j}^l$$

即第$$l$$层的格拉姆矩阵用作特征矩阵，由于计算方法抛弃了位置信息，因此可以看做是对风格的描述。第$$i,j$$位置的元素用于描述第$$i$$和第$$j$$个响应的相关性。这可以看作是一个图形风格的代表。

为了让风格像上面的内容一样得到近似，我们采用相似的方法进行逼近。

$$E_c^l=\frac{1}{2}\mid \mid G^l-\overline{G^l}\mid \mid ^2$$

对误差求导可以得到

$$\frac{\partial E_s^l}{x^l_{h,w,k}}=(X^l)^T(G^l-\overline{G^l})_{i,j}$$

同样通过反向传播法则可以使目标图像和我们选取的图像风格逼近。

![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/StyleExperiment.png)

#### 2.5 测试

为了不失一般性，采用高斯噪声作为初始输入图像，选取一幅特殊风格的图像作为参考。其中

代表了内容特征的卷积层选择$$conv4\_2$$

代表了风格特征的卷积层选择$$conv1\_1,conv2\_1,conv3\_1,conv4\_1,conv5\_1$$

设内容误差权重为$$\alpha$$，设风格误差权重为$$\beta$$，则误差函数可以联合为

$$Loss_{total} = \alpha Loss_{content}+\beta Loss_{style}$$

即

$$Loss_{total} = \frac{1}{2}\alpha \mid \mid X^l-\overline{X^l}\mid \mid ^2+\beta \frac{1}{2}\mid \mid G^l-\overline{G^l}\mid \mid ^2$$

以下是训练了100次后的结果，耗时约10分钟。

![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/1542695387.result.png)

使用GPU加强训练了2000次，得到结果对比如下

![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/LX.jpg)

*图取自 北京理工大学 良乡图书馆*

![](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/1620.png)



原论文中没有提及缺陷，此处进行一定的说明

1. 只能获取某种类型的风格。风格判定矩阵（无视位置的格拉姆矩阵）与卷积网络（局部连接匹配）的特点就决定了只能提取线条和色调这样的特征
2. 此时的风格迁移算法还不能理解图像的含义，只能根据特征进行匹配。匹配时只能将本身内容相似的图像进行混合，否则需要进行细致调参（本模型的超参数超过10个），但效果仍不理想。
3. 对于低对比度图像生成效果变差。
4. 迁移效率较低。模型每一次迭代都在训练CNN中的参数，完成一次迭代需要更新参数很多。相比之下斯坦福大学提出的fast neural style只需要做一次前馈就能完成风格的迁移。

