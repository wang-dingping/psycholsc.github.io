---
layout: post
comments: true
title:  "现代信号谱分析导论"
excerpt: "-"
date:   2019-03-13 16:42:24 +0000
categories: Notes
---

<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
---

## 现代信号谱分析导论

### 先修课程

本课程需要的先修课程为

- 线性代数
- 信号与系统
- 数字信号处理
- 随机过程

此处不对该课程内容做出过多的介绍。

### 概述

我们日常看到的信号都是随机信号。在通信与雷达中，我们的接收信号永远是一个依某种概率分布的信号，我们要根据这个结果进行对结果的“猜测”，从而得到正确的结果。详细内容不多介绍。信号谱分析也是一个相似的学科。我们接收到的同类型信号往往是一个随机过程，我们永远不能获取该过程的所有实现`implementation`，但是我们在单次测量中一定能依一定精度获取一个随机序列。注意单次随机过程仍是一个连续过程，但是我们的测量却只能获取一个离散序列。当然，如果我们以奈奎斯特频率以上的频率进行采样（实际中往往都是过采样），则能获取其中的全部信息，并且能通过滤波器将其完全恢复。因此我们就可以

> 根据这一个随机过程的实现的片段，估计整个信号的功率谱分布。

不过这是我个人的总结，书中介绍为

> 根据观察到的样本数据集估计平稳信号的总体功率谱

实际上《现代信号谱分析》这本书就是讲解这一部分内容，这句话就是全书的中心思想。

对信号谱进行估计是一个很值得研究的学科，目前也有很多人对该方向进行研究。信号谱的分析一般分为两类方法，这也是本册课程后面会重点讲到的内容。一类是**经典谱估计方法**，另一类是**现代谱估计方法**。两类方法主要内容如下

- 非参数化方法（经典谱估计方法）

    依赖于傅里叶变换的方法，有**相关图**法、**周期图**法等。

- 参数化模型方法（现代谱估计法）

    依赖于现有模型的方法，建立一个含较多参数的模型，然后根据信号的特点对这些模型的参数进行估计，最后将模型直接转化为功率谱的形式。常见的有自回归方法、最大熵法、最大似然估计法、超分辨率法等。

### 谱分析基础

首先我们对功率谱进行一个简单定义。功率谱的本质应该是对整个随机过程的全部实现进行功率谱计算并求平均的方法，因为一个随机过程的实现很多，单次实现很可能并不能完整代表整个过程（当然有各态历经性这个性质，利用一次实现就可以估计整个随机过程的数字参数）。

那么功率谱密度的定义就是


$$
\begin{equation}
\begin{split}
P_x(\omega)=\sum\limits_{m=-\infty}^{+\infty}r_x(m)e^{-j\omega m}
\end{split}
\tag{1}
\end{equation}
$$
这个定义实质上是维纳辛钦定理的表达。这里对该定理不做证明，但是该定理揭示了随机过程的**自相关函数**与随机信号的**功率谱密度**是一对傅里叶变换对。对于从未接触过相关内容的人，此处对其性质做出一些解释

- 随机信号的自相关函数，由于本身信号是采样结果，因此我们认为相关函数也是离散形式的。但是由于做了一个离散时间傅里叶变换，这里根据傅里叶变换的性质，功率谱密度是一个连续量。

- 一般随机过程的自相关函数都是非周期的，不过也是存在例外的。如果我们的自相关**序列**（这里注释一下，对于离散的信号来说，自相关**序列**比自相关**函数**更加符合）是非周期的，那么此时一个重要的性质为


    $$
    \begin{equation}
    \begin{split}
    r(0)=\overline{P}=\int_{-\pi}^{+\pi}P(\omega)d\omega
    \end{split}
    \tag{2}
    \end{equation}
    $$
    即周期功率谱密度在一个周期内的积分。这个表达式不唯一，至于为什么是周期的，这个需要自己查《信号与系统》

- 随机信号的自相关函数和功率谱密度分别从**时域**和**频域**反映随机序列的**二阶统计特性**

---

一个平稳随机信号可以分解为两个互不相关的随机振幅简谐振动的叠加。如果是一个窄带过程，则可以表达为**莱斯形式**，否则我们可以将其叠加为


$$
\begin{equation}
\begin{split}
x[n]=\sum\limits_{k=1}^{N}(a_k \cos n\omega_k +b_k \sin n\omega_k)
\end{split}
\tag{3}
\end{equation}
$$
其中两个随机振幅是均值为$$0$$，方差为$$\sigma^2$$的高斯过程，联合平稳。

自相关函数保存了序列的全部频率成分，并且依能量的形式保存了振幅的信息。

---

### 统计估计基础

统计估计使信号处理中一个常用的手段，实际上专门有学科为**统计信号处理**。说明白一点，统计估计这部分的目的就是，如何更好地**用随机信号的一次样本实现的有限长数据估计统计特征量**。统计特征可以是均值、方差等，也可以是相关序列与谱等。实际上我们这里使用统计更多时候是评估谱估计方法的性能。

根据观测数据来推断某个量$$\theta$$的过程称为统计估计问题，设随机过程$$X(n)$$的某个数字特征量的真值为$$\theta$$，但是我们并不知道，只能根据已知的短暂的序列对这个参数进行估计，估计值一般记为$$\hat \theta$$。显然我们的估计值是根据序列$$x$$得到的，因此我们认为
$$
\begin{equation}
\begin{split}
\hat\theta=f(x)
\end{split}
\tag{4}
\end{equation}
$$

我们这里的函数$$f$$不仅可以是线性函数，也可以是其他非线性函数，为了衡量估计的近似程度，我们一般引入若干指标

- `bias`，即**偏差**。
    $$
    \begin{equation}
    \begin{split}
    bias[\hat\theta]=E\{ \hat\theta - \theta \}
    \end{split}
    \tag{5}
    \end{equation}
    $$
    若偏差为$$0$$，就是**无偏估计**，若在取样点数趋于无穷时偏差也趋于$$0$$，则被认为是**渐近无偏估计**。

- `var`，即**方差**
    $$
    \begin{equation}
    \begin{split}
    var[\hat\theta]=E \{ (\hat\theta - E\{\hat\theta\})^2 \}
    \end{split}
    \tag{6}
    \end{equation}
    $$
    样本方差我们学过很多次了，就是描述各次估计相对于估计均值的偏离程度。

- `mse`，即**均方误差**

    均方误差的定义为
    $$
    \begin{equation}
    \begin{split}
    mse[\hat\theta]=E\{(\hat\theta - \theta)^2\}=var[\theta]+(bias[\hat\theta])^2
    \end{split}
    \tag{7}
    \end{equation}
    $$
    如果均方误差是$$0$$，我们说这还是一个一致估计；如果均方误差在点数趋近于无穷的时候逼近$$0​$$，我们就说这是一个渐近一致估计。

---

接下来简单介绍一下相关参数的估计方法。

首先是我们关于**均值**的估计。对于一个因果稳定的系统，均值就是直接求和除以点数，这就是简单的求平均。需要注意期望与均值实际上不是相同含义，期望一般是统计意义上的平均，这时我们认为是对随机过程的所有实现进行统计；但是均值就是简单的求平均过程。

然后简单说以下**方差**的估计。这里的方差就是均值与实际数值之间差异的平方的平均值。由于样本有限，因此仍然是有限点数的平均结果。如果我们有
$$
\begin{equation}
\begin{split}
bias[\hat\sigma_X^2]=0
\end{split}
\tag{8}
\end{equation}
$$
我们就说这个方差的估计是$$\sigma_X^2$$的无偏一致估计。

对于自相关序列的估计，一般有两个方法。一种是
$$
\begin{equation}
\begin{split}
\hat r_x(m)=\frac{1}{N}\sum\limits_{n=0}^{N-1}x_N(n)x_N(n+m)
\end{split}
\tag{9}
\end{equation}
$$
这个估计是最常用的估计。因为点数是有限的，因此在位移求乘积并均值的过程中，不同位置求和的点数不同。例如在计算$$\hat r(0)$$的时候，我们是$$N$$个点计算，所以除以$$N$$是没有问题的；计算其他位置的时候，求和点数就会下降，但是此时我们仍然除以$$N$$，这就是这个方法估计的特点。

这里不加推导地说明，该估计是一个有偏估计，偏差为
$$
\begin{equation}
\begin{split}
bias[\hat r_x(m)]=-\frac{\mid m \mid}{N}r_x(m)
\end{split}
\tag{10}
\end{equation}
$$
这个估计是个有偏估计，但是随着取样点数$$N$$的增加，这个结果是渐近无偏估计。

对这个算法进行进一步的理解，我们可以发现，实际上这个估计就相当于给相关函数加了一个三角窗。

另外此算法的方差在$$N\to \infty$$的时候趋向于$$0$$，因此是一个渐近无偏**一致**估计。

另一种方法是
$$
\begin{equation}
\begin{split}
\hat r_x(m)=\frac{1}{N-\mid m \mid}\sum\limits_{n=0}^{N-1-\mid m \mid}x_N(n)x_N(n+\mid m\mid)
\end{split}
\tag{11}
\end{equation}
$$
这个方法的本质就是在处理均值的时候严格按照求和点数进行。这样可以保证所有的均值都是基于求和点数的，不会出现上述的加三角窗的情况，而且是一个**无偏一致估计**，但是当我们的$$m$$增大的时候，方差会远大于上一种方法。

> 实际上相关函数的估计，按照上述的两种方法来看，就是一个求平均的差异，参与平均的数据越多，靠近中心位置的估值就更加可靠，但是显然点数是有限的，因此估计的时候就会产生误差，这也就是功率谱估计的误差的来源。

---

### 功率谱及其估计

介绍完了基础理论，这里要开始介绍主要内容了。


